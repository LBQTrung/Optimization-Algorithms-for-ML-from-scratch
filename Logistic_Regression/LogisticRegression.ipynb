{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxWF5Q3gtMcf"
      },
      "source": [
        "### 1. Tổng quan cơ sở toán"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UmJF-e9xlad"
      },
      "source": [
        "#### 1.1 Hàm sigmoid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO4Ibiwnxq6V"
      },
      "source": [
        "Hàm sigmoid là hàm số dùng trong phân loại nhị phân, có công thức như sau:\n",
        "$$g(x) = \\frac{1}{1 + e^{-z}} $$\n",
        "\n",
        "Bên dưới là độ thị của hàm sigmoid:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3hkHyOFx41P"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5m4ejn9x5Wf"
      },
      "source": [
        "Hàm sigmoid dùng trong phân loại nhị phân vì:\n",
        "- Đầu ra của hàm này nằm trong khoảng (0, 1), nên có thể biểu diễn đầu ra dưới dạng xác suất $P(y=1 | x, w)$\n",
        "- Khi giá trị của đầu vào càng nhỏ (trong trường hợp này chính là khoảng cách đến đường phân chia - boundary) thì đầu ra sẽ tiến gần đến 0.5\n",
        "- Khi giá trị của đầu vào càng lớn và âm (tức nằm về 1 phía nào đó) thì giá trị đầu ra sẽ tiến đến 0\n",
        "- Khi giá trị của đầu vào càng lớn và dương (tức nằm về 1 phía nào đó) thì giá trị đầu ra sẽ tiến đến 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smkUR-K6u8r_"
      },
      "source": [
        "#### 1.2 Mô hình Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHuWlfvXvAdc"
      },
      "source": [
        "Bài toán Logistic Regression là một bài toán phân loại nhị phân có thể được biểu diễn bằng đơn giản bằng ánh xạ sau:\n",
        "\n",
        "$$ f: R^n → \\{0, 1\\} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsgjB0Q0veCT"
      },
      "source": [
        "Mô hình hồi quy logistic được biểu diễn như sau:\n",
        "\n",
        "$$ \\hat{y}= \\frac{1}{1 + e^{- x^Tw}} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lADwN393wtzx"
      },
      "source": [
        "Ghi chú:\n",
        "- $x^Tw$ là siêu phẳng phân chia tập dữ liệu thành 2 phần cho mục đích phân loại nhị phân (Đã được giải thích về bias ở trong phần Linear Regression trước đó)\n",
        "- $g(x) = \\frac{1}{1 + e^{-z}} $ là hàm sigmoid đã được trình bày ở trên"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OygNN1TRy4lU"
      },
      "source": [
        "#### 1.3 Hàm mất mát"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bOrHQrfy7AE"
      },
      "source": [
        "**Loss function** là hàm mất mát với từng điểm dữ liệu sẽ được biểu diễn như sau:\n",
        "\n",
        "$$ L(\\hat{y}, y) = -(ylog(\\hat{y}) + (1-y)log(1-\\hat{y})) $$\n",
        "\n",
        "Với:\n",
        "- $\\hat{y}$ là giá trị dự đoán\n",
        "- y là giá trị thực tế\n",
        "- $log$ thực ra là $ln$ (Trong Machine learning người ta thường ký hiệu là $log$)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbKSoSx6zs6L"
      },
      "source": [
        "Hàm trên thực sự hợp lý vì khi giá trị thực tế vì:\n",
        "- Khi $y=1$: hàm số trên được viết lại thành $L(\\hat{y}, y) = -log(\\hat{y})$. Khi giá trị dự đoán $\\hat{y}$ tiến càng gần 1 thì giá trị của hàm mất mát sẽ tiến về 0 và ngược lại khi $\\hat{y}$ càng tiến về 0 (tức càng xa giá trị đúng đắn) thì giá trị hàm mất mát sẽ rất lớn.\n",
        "- Khi $y=0$: hàm số trên được viết lại thành $L(\\hat{y}, y) = -log(1-\\hat{y})$. Khi giá trị dự đoán $\\hat{y}$ tiến càng gần 0 thì giá trị của hàm mất mát sẽ tiến về 0 và ngược lại khi $\\hat{y}$ càng tiến về 1 (tức càng xa giá trị đúng đắn) thì giá trị hàm mất mát sẽ rất lớn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xrc1soFw0zVx"
      },
      "source": [
        "**Cost function** là hàm mất mát cho toàn bộ tập dữ liệu, điều đó có nghĩa là ta phải tính giá trị trung bình:\n",
        "$$ J(w) = - \\frac{1}{m} \\sum_{i=0}^m(y_ilog(\\hat{y}_i) + (1-y_i)log(1-\\hat{y}_i)) $$\n",
        "\n",
        "Với:\n",
        "- m là tổng số điểm dữ liệu\n",
        "- $\\hat{y}$ là giá trị mô hình dự đoán\n",
        "- $y_i$ là giá trị thực tế"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwoBvoOR3a-9"
      },
      "source": [
        "Cost function có đạo hàm cũng tương đối dễ tính chỉ cần áp dụng đạo hàm của hàm sigmoid:\n",
        "$$ g^{'}(z)=g(z)(1-g(z))$$\n",
        "\n",
        "Ta sẽ được kết quả sau:\n",
        "$$ \\nabla J(w)=\\frac{1}{m}  X^T(Xw - y)$$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kHy2ubCtSCW"
      },
      "source": [
        "### 2. Cài đặt thuật toán"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ltZWRL9NtoRe"
      },
      "outputs": [],
      "source": [
        "# Import một số thư viện cần thiết\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01, mini_batch_size=None, num_epochs=1000, epsilon=1e-8, \n",
        "                 optimizer='GD', beta=0.9, beta1=0.9, beta2=0.999, print_costs=False):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_epochs = num_epochs\n",
        "        self.print_costs = print_costs\n",
        "        self.epsilon = epsilon\n",
        "        self.optimizer = optimizer\n",
        "        self.beta = beta # Dùng cho Momentum\n",
        "        self.mini_batch_size = mini_batch_size\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "        self.v_dw = None # Dùng cho Momentum và Adam\n",
        "        self.v_db = None # Dùng cho Momentum và Adam\n",
        "        self.s_dw = None # Dùng cho Adam \n",
        "        self.s_db = None # Dùng cho Adam\n",
        "        self.t = 0 # Dùng bias corrected trong adam\n",
        "        self.beta1 = beta1 # Dùng cho Adam\n",
        "        self.beta2 = beta2 # Dùng cho Adam\n",
        "        self.costs = []\n",
        "\n",
        "    def initialize_params(self, shape):\n",
        "        self.w = np.zeros((shape, 1))\n",
        "        self.b = 0\n",
        "        if (self.optimizer == 'momentum'):\n",
        "            print('momentum')\n",
        "            self.v_dw = np.zeros(self.w.shape)\n",
        "            self.v_db = 0\n",
        "        elif (self.optimizer == 'adam'):\n",
        "            print('adam')\n",
        "            self.v_dw = np.zeros(self.w.shape)\n",
        "            self.v_db = 0\n",
        "            self.s_dw = np.zeros(self.w.shape)\n",
        "            self.s_db = 0\n",
        "    \n",
        "\n",
        "    def y_hat(self, X):\n",
        "        z = np.dot(X, self.w) + self.b\n",
        "        y_hat = 1 / (1 + np.exp(-z))\n",
        "        return y_hat\n",
        "\n",
        "    def cost_function(self, X, y):\n",
        "        m = X.shape[0]\n",
        "        # Thêm epsilon để tránh trường hợp log(0)\n",
        "        J = -1/m * np.sum(y * np.log(self.y_hat(X)+self.epsilon) + \n",
        "                          (1-y) * np.log(1 - self.y_hat(X) + self.epsilon))\n",
        "        return J\n",
        "    \n",
        "    '''Gradient Descent'''\n",
        "    def gradient(self, X, y):\n",
        "        m = X.shape[0]\n",
        "        y_pred = self.y_hat(X)\n",
        "        dw = 1/m * np.dot(X.T, y_pred - y)\n",
        "        db = 1/m * np.sum(y_pred - y)\n",
        "        return dw, db\n",
        "\n",
        "    def gradient_descent(self, X, y):\n",
        "        for i in range(self.num_epochs):\n",
        "            dw, db = self.gradient(X, y)\n",
        "            cost = self.cost_function(X, y)\n",
        "            self.w = self.w - self.learning_rate * dw\n",
        "            self.b = self.b - self.learning_rate * db\n",
        "\n",
        "            if self.print_costs and i % 100 == 0:\n",
        "                print(f'Cost value after {i}: {cost}')\n",
        "            self.costs.append(cost)\n",
        "        \n",
        "\n",
        "\n",
        "    '''Min-batch Gradient Desent'''\n",
        "    def random_mini_batches(self, X, y, mini_batch_size = 64, seed = 0):\n",
        "        \"\"\"\n",
        "        Creates a list of random minibatches from (X, y)\n",
        "        \n",
        "        Arguments:\n",
        "        X -- input data, of shape (number of examples, input size)\n",
        "        y -- true \"label\" vector of shape (number of examples, 1)\n",
        "        mini_batch_size -- size of the mini-batches, integer\n",
        "        \n",
        "        Returns:\n",
        "        mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
        "        \"\"\"\n",
        "        np.random.seed(seed)            \n",
        "        m = X.shape[1]                  \n",
        "        mini_batches = []\n",
        "\n",
        "        # Step 1: Shuffle (X, Y)\n",
        "        permutation = list(np.random.permutation(m))\n",
        "        shuffled_X = X[permutation, :]\n",
        "        shuffled_y = y[permutation, :]\n",
        "\n",
        "        # Step 2 - Partition (shuffled_X, shuffled_Y).\n",
        "        # Cases with a complete mini batch size only i.e each of 64 examples.\n",
        "        num_complete_minibatches = math.floor(m / mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
        "        for k in range(0, num_complete_minibatches):\n",
        "            mini_batch_X = shuffled_X[k*mini_batch_size: (k+1) * mini_batch_size, :]\n",
        "            mini_batch_Y = shuffled_y[k*mini_batch_size: (k+1) * mini_batch_size, :]\n",
        "            mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "            mini_batches.append(mini_batch)\n",
        "        \n",
        "        # For handling the end case (last mini-batch < mini_batch_size i.e less than 64)\n",
        "        if m % mini_batch_size != 0:\n",
        "            mini_batch_X = shuffled_X[num_complete_minibatches*mini_batch_size:, :]\n",
        "            mini_batch_Y = shuffled_y[num_complete_minibatches*mini_batch_size:, :]\n",
        "            mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "            mini_batches.append(mini_batch)\n",
        "        \n",
        "        return mini_batches\n",
        "\n",
        "    # Cập nhật trọng số với Gradient Descent truyền thống\n",
        "    def update_parameters_with_GD(self, X, y):\n",
        "        dw, db = self.gradient(X, y)\n",
        "        self.w = self.w - self.learning_rate * dw\n",
        "        self.b = self.b - self.learning_rate * db\n",
        "    \n",
        "    # Khởi tạo velocity cho momentum\n",
        "    def initialize_velocity(self):\n",
        "        self.v_dw = np.zeros(self.w.shape)\n",
        "        self.v_db = 0\n",
        "    \n",
        "    # Cập nhật trọng số với Gradient Descent with Momentum\n",
        "    def update_parameters_with_momentum(self, X, y):\n",
        "        dw, db = self.gradient(X, y)\n",
        "        self.v_dw = self.beta * self.v_dw + (1-self.beta) * dw\n",
        "        self.v_db = self.beta * self.v_db + (1-self.beta) * db\n",
        "        self.w -= self.learning_rate * self.v_dw\n",
        "        self.b -= self.learning_rate * self.v_db\n",
        "    \n",
        "    # Cập nhật trọng số với adam\n",
        "    def update_parameters_with_adam(self, X, y):\n",
        "        dw, db = self.gradient(X, y)\n",
        "        #Momentum\n",
        "        self.v_dw = self.beta1 * self.v_dw + (1-self.beta1) * dw\n",
        "        self.v_db = self.beta1 * self.v_db + (1-self.beta1) * db\n",
        "        v_dw_corrected = self.v_dw / (1-self.beta1 ** self.t)\n",
        "        v_db_corrected = self.v_db / (1-self.beta1 ** self.t)\n",
        "\n",
        "        #RMSprop\n",
        "        self.s_dw = self.beta2 * self.s_dw + (1-self.beta2) * dw**2\n",
        "        self.s_db = self.beta2 * self.s_db + (1-self.beta2) * db**2\n",
        "        s_dw_corrected = self.s_dw / (1-self.beta2 ** self.t)\n",
        "        s_db_corrected = self.s_db / (1-self.beta2 ** self.t)\n",
        "\n",
        "        self.w -= self.learning_rate * v_dw_corrected / (s_dw_corrected ** (1/2) + self.epsilon)\n",
        "        self.b -= self.learning_rate * v_db_corrected / (s_db_corrected ** (1/2) + self.epsilon)\n",
        "\n",
        "    def mini_batch_gradient_descent(self, X, y):\n",
        "        m = X.shape[0]\n",
        "        seed = 0\n",
        "        # Khai báo dùng cho momentum và adam\n",
        "        v_w = np.zeros(self.w.shape)\n",
        "        v_b = 0\n",
        "        for i in range(self.num_epochs):\n",
        "            seed = seed + 1\n",
        "            minibatches = self.random_mini_batches(X, y, self.mini_batch_size, seed)\n",
        "            cost_total = 0\n",
        "\n",
        "            for minibatch in minibatches:\n",
        "                (minibatch_X, minibatch_y) = minibatch\n",
        "                cost = self.cost_function(minibatch_X, minibatch_y)\n",
        "                cost_total += cost\n",
        "\n",
        "                if (self.optimizer == 'GD'):\n",
        "                    self.update_parameters_with_GD(minibatch_X, minibatch_y)\n",
        "\n",
        "                elif (self.optimizer == 'momentum'):\n",
        "                    self.update_parameters_with_momentum(minibatch_X, minibatch_y)\n",
        "\n",
        "                elif (self.optimizer == 'adam'):\n",
        "                    self.t += 1 # Cập nhật bias correction\n",
        "                    self.update_parameters_with_adam(minibatch_X, minibatch_y)\n",
        "                    \n",
        "            cost_avg = cost_total / m\n",
        "\n",
        "            if self.print_costs and i % 100 == 0 and i > 0:\n",
        "                print(f'Cost value after {i}: {cost_avg}')\n",
        "                self.costs.append(cost_avg)\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        y = y.reshape(-1, 1)\n",
        "        self.initialize_params(X.shape[1])\n",
        "        if (self.mini_batch_size == 1 or self.mini_batch_size == None):\n",
        "            print(\"Batch Gradient Descent...\")\n",
        "            self.gradient_descent(X, y)\n",
        "        else:\n",
        "            if (self.mini_batch_size == X.shape[0]):\n",
        "                print(\"Stochastic Gradient Descent...\")\n",
        "            else:\n",
        "                print(f\"Mini-batch Gradient Descent with {self.mini_batch_size} mini-batches ...\")\n",
        "            self.mini_batch_gradient_descent(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = self.y_hat(X)\n",
        "        return (y_pred > 0.5).astype(int)\n",
        "\n",
        "    def plot_cost_history(self):\n",
        "        if self.print_costs:\n",
        "            plt.plot(range(self.num_epochs), self.costs)\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.ylabel(\"Cost\")\n",
        "            plt.title(\"Cost History\")\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIM6gvpNtoYW"
      },
      "source": [
        "### 3. Triển khai thuật toán"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1 Đọc tập dữ liệu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Em triển khai trên tập dữ liệu credit card vì nó đủ lớn và hạn chế bị lệch label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SVrG46iutwI3",
        "outputId": "a5718cc3-f83a-4c0a-c4af-dbe5f17dc4cb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = pd.read_csv('logistic_dataset.csv')\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CGcAl9Cu9MxB"
      },
      "outputs": [],
      "source": [
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.2 Tiền xử lý dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2636nkfN9O7h"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,\n",
        "                                                    random_state=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xvv9DmJB9Tc5"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler1 = StandardScaler()\n",
        "X_train = scaler1.fit_transform(X_train)\n",
        "X_test = scaler1.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class SVM:\n",
        "    def __init__(self, learning_rate=0.01, num_epochs=1000, C=1.0, mini_batch_size=None,\n",
        "                 epsilon=1e-8, optimizer='GD', beta=0.9, beta1=0.9, \n",
        "                 beta2=0.999, print_costs=False):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_epochs = num_epochs\n",
        "        self.C = C\n",
        "        self.print_costs = print_costs\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "\n",
        "        self.mini_batch_size = mini_batch_size\n",
        "        self.epsilon = epsilon\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        self.costs = [] # Dùng cho batch\n",
        "        self.epochs_for_print = [] # Dùng cho batch\n",
        "\n",
        "        self.all_costs = [] # Dùng cho mini-batch để trực quan hơn\n",
        "\n",
        "        self.beta = beta # Dùng cho Momentum\n",
        "        self.beta1 = beta1 # Dùng cho Adam\n",
        "        self.beta2 = beta2 # Dùng cho Adam\n",
        "        self.mini_batch_size = mini_batch_size\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "        self.v_dw = None # Dùng cho Momentum và Adam\n",
        "        self.v_db = None # Dùng cho Momentum và Adam\n",
        "        self.s_dw = None # Dùng cho Adam \n",
        "        self.s_db = None # Dùng cho Adam\n",
        "        \n",
        "\n",
        "    def initialize_params(self, shape):\n",
        "        self.w = np.zeros((shape, 1))\n",
        "        self.b = 0\n",
        "        if (self.optimizer == 'momentum'):\n",
        "            self.v_dw = np.zeros(self.w.shape)\n",
        "            self.v_db = 0\n",
        "        elif (self.optimizer == 'adam'):\n",
        "            self.v_dw = np.zeros(self.w.shape)\n",
        "            self.v_db = 0\n",
        "            self.s_dw = np.zeros(self.w.shape)\n",
        "            self.s_db = 0\n",
        "\n",
        "    def margin(self, X, y):\n",
        "        m = X.shape[0]\n",
        "        margin = 1 - y * (np.dot(X, self.w) + self.b)\n",
        "        margin = np.maximum(0, margin)\n",
        "        return margin\n",
        "\n",
        "    def cost_function(self, X, y):\n",
        "        m = X.shape[0]\n",
        "        margin = self.margin(X, y)\n",
        "        regularization = 1 / 2 * np.dot(self.w.T, self.w)\n",
        "        J = 1 / m * np.sum(margin) + self.C * regularization\n",
        "        return J[0][0]\n",
        "\n",
        "    def gradient(self, X, y):\n",
        "        m = X.shape[0]\n",
        "        margin = self.margin(X, y)\n",
        "        loss = np.where(margin > 0, 1, 0)  # Loss for each data point\n",
        "        loss = loss.reshape(-1, 1)\n",
        "\n",
        "        dw = -(1 / m) * np.dot(X.T, loss * y) + self.C * self.w\n",
        "        db = -(1 / m) * np.sum(loss * y)\n",
        "\n",
        "        return dw, db\n",
        "\n",
        "    '''Min-batch Gradient Desent'''\n",
        "    def random_mini_batches(self, X, y, mini_batch_size = 64, seed = 0):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            - X: Dữ liệu đầu vào\n",
        "            - y: Nhãn lớp \n",
        "            - mini_batch_size: số lượng example trong mỗi mini-batch\n",
        "            - seed: giá trị để đảm bảo mỗi lần random sẽ khác biệt hoàn toàn\n",
        "\n",
        "        Output:\n",
        "            mini_batches: list của những phần tử (mini_batch_X, mini_batch_Y)\n",
        "        \"\"\"\n",
        "        np.random.seed(seed)            \n",
        "        m = X.shape[1]                  \n",
        "        mini_batches = []\n",
        "\n",
        "        # Bước 1: Xáo trộn\n",
        "        permutation = list(np.random.permutation(m))\n",
        "        shuffled_X = X[permutation, :]\n",
        "        shuffled_y = y[permutation, :]\n",
        "\n",
        "        # Bước 2: Phân chia X, y thành các mini-batch\n",
        "        num_complete_minibatches = math.floor(m / mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
        "        for k in range(0, num_complete_minibatches):\n",
        "            mini_batch_X = shuffled_X[k*mini_batch_size: (k+1) * mini_batch_size, :]\n",
        "            mini_batch_Y = shuffled_y[k*mini_batch_size: (k+1) * mini_batch_size, :]\n",
        "            mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "            mini_batches.append(mini_batch)\n",
        "        \n",
        "        # Xử lý mini-batch cuối cùng\n",
        "        if m % mini_batch_size != 0:\n",
        "            mini_batch_X = shuffled_X[num_complete_minibatches*mini_batch_size:, :]\n",
        "            mini_batch_Y = shuffled_y[num_complete_minibatches*mini_batch_size:, :]\n",
        "            mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "            mini_batches.append(mini_batch)\n",
        "        \n",
        "        return mini_batches\n",
        "\n",
        "    # Cập nhật trọng số với Gradient Descent truyền thống\n",
        "    def update_parameters_with_GD(self, X, y):\n",
        "        dw, db = self.gradient(X, y)\n",
        "        self.w = self.w - self.learning_rate * dw\n",
        "        self.b = self.b - self.learning_rate * db\n",
        "    \n",
        "    # Cập nhật trọng số với Gradient Descent with Momentum\n",
        "    def update_parameters_with_momentum(self, X, y):\n",
        "        dw, db = self.gradient(X, y)\n",
        "        self.v_dw = self.beta * self.v_dw + (1-self.beta) * dw\n",
        "        self.v_db = self.beta * self.v_db + (1-self.beta) * db\n",
        "        self.w -= self.learning_rate * self.v_dw\n",
        "        self.b -= self.learning_rate * self.v_db\n",
        "    \n",
        "    # Cập nhật trọng số với adam\n",
        "    def update_parameters_with_adam(self, X, y):\n",
        "        dw, db = self.gradient(X, y)\n",
        "        #Momentum\n",
        "        self.v_dw = self.beta1 * self.v_dw + (1-self.beta1) * dw\n",
        "        self.v_db = self.beta1 * self.v_db + (1-self.beta1) * db\n",
        "\n",
        "        #RMSprop\n",
        "        self.s_dw = self.beta2 * self.s_dw + (1-self.beta2) * dw**2\n",
        "        self.s_db = self.beta2 * self.s_db + (1-self.beta2) * db**2\n",
        "\n",
        "        self.w -= self.learning_rate * self.v_dw / (self.s_dw ** (1/2) + self.epsilon)\n",
        "        self.b -= self.learning_rate * self.v_db / (self.s_db ** (1/2) + self.epsilon)\n",
        "\n",
        "    def mini_batch_gradient_descent(self, X, y):\n",
        "        m = X.shape[0]\n",
        "        seed = 0\n",
        "        for i in range(self.num_epochs):\n",
        "            seed = seed + 1\n",
        "            minibatches = self.random_mini_batches(X, y, self.mini_batch_size, seed)\n",
        "            cost_total = 0\n",
        "\n",
        "            for minibatch in minibatches:\n",
        "                (minibatch_X, minibatch_y) = minibatch\n",
        "                cost = self.cost_function(minibatch_X, minibatch_y)\n",
        "                \n",
        "                cost_total += cost\n",
        "                if (self.optimizer == 'GD'):\n",
        "                    self.update_parameters_with_GD(minibatch_X, minibatch_y)\n",
        "\n",
        "                elif (self.optimizer == 'momentum'):\n",
        "                    self.update_parameters_with_momentum(minibatch_X, minibatch_y)\n",
        "\n",
        "                elif (self.optimizer == 'adam'):\n",
        "                    self.update_parameters_with_adam(minibatch_X, minibatch_y)\n",
        "                    \n",
        "            cost_avg = cost_total / m\n",
        "            self.all_costs.append(cost_avg)\n",
        "            \n",
        "            if self.print_costs and i % 100 == 0 and i > 0:\n",
        "                print(f'Cost value after {i}: {cost_avg}')\n",
        "                self.costs.append(cost_avg)\n",
        "                self.epochs_for_print.append(i)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        y = y.reshape(-1, 1)\n",
        "        y = np.where(y == 1, 1, -1)\n",
        "        self.initialize_params(X.shape[1])\n",
        "        if (self.mini_batch_size == 1 or self.mini_batch_size == None):\n",
        "            print(\"Batch Gradient Descent...\")\n",
        "            self.mini_batch_gradient_descent(X, y)\n",
        "        else:\n",
        "            if (self.mini_batch_size == X.shape[0]):\n",
        "                print(\"Stochastic Gradient Descent...\")\n",
        "            else:\n",
        "                print(f\"Mini-batch Gradient Descent with {self.mini_batch_size} mini-batches ...\")\n",
        "            self.mini_batch_gradient_descent(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = np.dot(X, self.w) + self.b\n",
        "        y_pred = np.sign(y_pred)\n",
        "        y_pred = np.where(y_pred == 1, 1, 0)\n",
        "        return y_pred\n",
        "\n",
        "    def plot_cost_history(self):\n",
        "        if self.print_costs:\n",
        "            import matplotlib.pyplot as plt\n",
        "            if self.mini_batch_size > 1:\n",
        "                plt.plot(range(self.num_epochs), self.all_costs)\n",
        "                plt.xlabel('Iterations')\n",
        "            else:\n",
        "                plt.plot(self.epochs_for_print, self.costs)\n",
        "                plt.xlabel(\"Epochs\")\n",
        "            plt.ylabel(\"Cost\")\n",
        "            plt.title(\"Cost History\")\n",
        "            plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mini-batch Gradient Descent with 64 mini-batches ...\n",
            "Cost value after 100: 4.096786342396006e-08\n",
            "Cost value after 200: 1.098681739701979e-08\n",
            "Cost value after 300: 6.4993810430712265e-09\n",
            "Cost value after 400: 5.8663863647414025e-09\n",
            "Cost value after 500: 6.089308053473683e-09\n",
            "Cost value after 600: 5.4756279898426e-09\n",
            "Cost value after 700: 6.110876264645224e-09\n",
            "Cost value after 800: 5.7437391098486436e-09\n",
            "Cost value after 900: 5.98529725608243e-09\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9992626663389628\n"
          ]
        }
      ],
      "source": [
        "svm_gd = SVM(learning_rate=0.03, num_epochs=1000, C=0.3,\n",
        "          mini_batch_size=64, print_costs=True,\n",
        "          optimizer='momentum')\n",
        "svm_gd.fit(X_train, y_train)\n",
        "svm_gd.plot_cost_history()\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred1 = svm_gd.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred1)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "adam\n",
            "Mini-batch Gradient Descent with 64 mini-batches ...\n"
          ]
        }
      ],
      "source": [
        "logistic_regression = LogisticRegression(learning_rate=0.03, num_epochs=100, \n",
        "                                         mini_batch_size=64, optimizer='adam', \n",
        "                                         print_costs=True)\n",
        "logistic_regression.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy:  0.8025350233488993\n"
          ]
        }
      ],
      "source": [
        "y_pred = logistic_regression.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dLgESEL9dZa",
        "outputId": "3c50cf12-1539-4f0b-b4d4-58fd9fbe507c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kiểm tra X_train_scratch: \n",
            " [[  1.          -0.50477201   0.61522485   0.09009756   0.39918516\n",
            "    0.39793312  -0.43465629  -0.60619949  -0.07487182  -0.0244909\n",
            "   -0.09968893   0.11734731   1.50159642   0.7091484   -0.59534756\n",
            "    0.63106425   0.43946149   0.54387928  -0.65475815  -0.02110364\n",
            "    0.12211058  -0.18363096  -0.27630964  -0.9075095    0.25627482\n",
            "    0.84092951   0.25706794   0.13967233  -0.09384072   0.02757396\n",
            "   -0.34998492]\n",
            " [  1.           0.97113071   0.10935485   0.59750826  -0.49657022\n",
            "   -0.78794695   1.00070866  -0.86703373   1.33728195  -0.37422486\n",
            "   -0.84440453  -0.48423434   0.72558901   1.17469485   1.08098667\n",
            "    0.63861028  -0.97394613  -0.42841776  -0.9827763    0.05679476\n",
            "    0.41236923  -0.13396273   0.36208642   1.20303957  -0.63801766\n",
            "   -0.52164205   0.47839895   0.34420379  -0.01699563   0.01515803\n",
            "   -0.34638764]\n",
            " [  1.          -1.81008666  -2.36017966   1.02700412  -2.06027337\n",
            "    3.06059177  -1.37327549  -0.74662569  -3.78219219   0.39567558\n",
            "    0.43032453  -5.14105563   4.70697737 -10.85788494   0.10381842\n",
            "   -9.83377276  -0.88425565  -8.62025582 -11.56852406  -4.91955946\n",
            "    2.1358673   -0.05225458   0.65956395   0.2027493    0.18906081\n",
            "   -0.35806221  -0.26540648  -0.87940037  -2.51524249   2.69905367\n",
            "   -0.35354177]\n",
            " [  1.           1.41350138  -1.77010266   2.03877494  -1.95086512\n",
            "   -0.68844201  -0.89934247  -0.69368459  -0.81344531   1.9131598\n",
            "    0.4847363    0.56786738  -2.47182344   0.6280459    0.34293849\n",
            "    1.34388581  -0.43203893   0.84088943   0.07949941  -0.35768836\n",
            "    0.08604816   0.36579795  -0.47667977  -1.35987726   0.39580579\n",
            "   -1.71948897   0.2077607    0.45413696   0.19334722  -0.28958757\n",
            "   -0.28527437]\n",
            " [  1.          -0.63338699   0.28348261  -1.26695213  -0.46086237\n",
            "   -0.25723307  -0.91576182  -0.4173396    0.11605791  -0.19783226\n",
            "   -0.54523016   0.50445938  -1.58904486  -1.61005992  -1.69683745\n",
            "    0.67863298   1.32048728  -1.05148488  -0.2113822    1.80461888\n",
            "   -0.70895016   0.48149904  -0.25058879  -1.66869212  -0.72407596\n",
            "   -0.76114477   0.26845925   2.17723185  -0.42604763   0.22180786\n",
            "    1.57706372]]\n"
          ]
        }
      ],
      "source": [
        "new_1_column = np.ones((X_train.shape[0], 1), dtype=int)\n",
        "X_train_scratch = np.hstack((new_1_column, X_train))\n",
        "print(\"Kiểm tra X_train_scratch: \\n\", X_train_scratch[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4IQMvTj9efY",
        "outputId": "2d998031-d6cd-495b-ec4f-ade107910797"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kiểm tra X_test_scratch: \n",
            " [[ 1.00000000e+00 -9.04600964e-01  5.80349176e-01 -4.02966758e-01\n",
            "   1.71366579e-01  3.33829598e-01 -6.86283443e-01 -2.27755004e-01\n",
            "  -3.76398676e-01  5.31720555e-02 -8.81060569e-01  9.70819381e-01\n",
            "   4.09357128e-01 -6.25120820e-01 -1.73330206e+00  7.89280265e-01\n",
            "   4.18900085e-01 -1.02973845e+00 -5.72357604e-01  2.55459403e+00\n",
            "  -1.02794532e+00 -6.09450460e-01 -3.61847487e-01 -8.25489504e-01\n",
            "  -1.70124764e-01 -1.57594391e-01  7.84623123e-01 -6.78537116e-01\n",
            "   3.23018766e-02  8.37539510e-02  4.62004721e-02]\n",
            " [ 1.00000000e+00 -4.48246283e-01 -5.77511242e-01  4.92808846e-01\n",
            "   5.90732525e-01 -3.89164545e-01  1.34407768e+00  3.20440260e+00\n",
            "  -4.69365357e-01  1.10801148e+00  1.07616938e-01 -4.62131735e-01\n",
            "  -7.38683015e-01 -2.11552220e-02 -1.04237617e-01 -2.85286024e-01\n",
            "   2.53105720e-01  3.26235073e-01 -7.43040530e-01  6.72684338e-01\n",
            "   5.16723463e-01  4.33772090e-03 -5.82181469e-02 -2.42065147e-01\n",
            "  -5.42019002e-01  1.64981238e+00  8.69094150e-01 -8.54768601e-01\n",
            "  -1.09723366e+00 -6.69628989e-01 -3.17609431e-01]\n",
            " [ 1.00000000e+00  1.28090601e+00  1.04642907e+00  3.18741406e-03\n",
            "  -7.92739142e-01  1.12971239e+00  3.66364032e-01  1.61146621e-01\n",
            "  -8.02180861e-02 -6.51545741e-02 -7.54736158e-01  1.21886461e+00\n",
            "  -1.67182497e-01  4.46486689e-01  9.22895367e-01  8.69278257e-03\n",
            "  -1.49896975e+00  1.48295848e+00 -1.34139801e+00  5.50887424e-03\n",
            "  -3.24085524e-01 -9.86338424e-02  2.67353341e-01  8.97679672e-01\n",
            "  -8.99451550e-02 -1.44566100e+00 -2.66047562e-01  5.23923205e+00\n",
            "  -5.15990111e-01 -3.18108232e-01 -3.06494253e-01]\n",
            " [ 1.00000000e+00  1.26077241e+00 -3.52171041e-01  5.49349247e-01\n",
            "  -8.62535918e-01 -1.52110909e+00  2.93351269e+00  2.18082707e+00\n",
            "   1.26753270e+00  3.68420062e-01 -1.03052276e+00 -1.12445257e+00\n",
            "   3.31767962e-01 -6.81017292e-01 -6.29239208e-01 -6.03488946e-01\n",
            "   2.90066509e-01  6.39821168e-02  2.56063164e-01 -2.26267915e-01\n",
            "  -1.08295626e+00  1.59482351e-01 -2.55697576e-02 -1.78011691e-01\n",
            "  -8.91858099e-01  1.07719436e+00  2.17149266e+00  1.33987626e+00\n",
            "  -6.31559443e-01 -5.60912690e-01 -1.97120894e-01]\n",
            " [ 1.00000000e+00  8.46032793e-01  4.47459284e-01 -1.43894657e+00\n",
            "  -9.69570136e-01  3.74573056e-01 -5.71262876e-01  2.17636826e-01\n",
            "   1.56163175e-01 -1.22855351e-01  9.10105378e-01 -2.22345036e-01\n",
            "  -1.40095740e+00  1.26396901e-01  7.23315162e-01 -5.94328948e-02\n",
            "   1.11599022e+00  9.65598706e-01 -1.10342658e+00  5.12886489e-01\n",
            "  -3.48009298e-01  1.51869189e+00  6.87429536e-01  2.19218819e-01\n",
            "  -6.72154215e-01  2.04680425e-01 -8.64803989e-01  1.23369929e+00\n",
            "  -3.93420507e-01  1.80907162e-01  2.18233572e+00]]\n"
          ]
        }
      ],
      "source": [
        "new_1_column = np.ones((X_test.shape[0], 1), dtype=int)\n",
        "X_test_scratch = np.hstack((new_1_column, X_test))\n",
        "X_test_scratch[:5]\n",
        "print(\"Kiểm tra X_test_scratch: \\n\", X_test_scratch[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pQaUOscy97gV"
      },
      "outputs": [],
      "source": [
        "y_train_scratch = y_train.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.3 Huấn luyện mô hình Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6NfeXSr-B49",
        "outputId": "78293056-1e34-4f91-c3af-29c9e6803dd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cost value after 0:  0.6931471805599451\n",
            "Cost value after 100:  0.2947150730295793\n",
            "Cost value after 200:  0.17350538887950115\n",
            "Cost value after 300:  0.12066387995407653\n",
            "Cost value after 400:  0.0920200156885429\n",
            "Cost value after 500:  0.0742952644061327\n",
            "Cost value after 600:  0.06233061990381779\n",
            "Cost value after 700:  0.053746304891999365\n",
            "Cost value after 800:  0.04730413651331407\n",
            "Cost value after 900:  0.04230025444322232\n",
            "Cost value after 1000:  0.03830651691353622\n",
            "Cost value after 1100:  0.03504821927203011\n",
            "Cost value after 1200:  0.03234133867036766\n",
            "Cost value after 1300:  0.030058138230021958\n",
            "Cost value after 1400:  0.028107269188783483\n",
            "Cost value after 1500:  0.02642172901509596\n",
            "Cost value after 1600:  0.02495128971345886\n",
            "Cost value after 1700:  0.0236575779339151\n",
            "Cost value after 1800:  0.022510785703103928\n",
            "Cost value after 1900:  0.021487415706771654\n"
          ]
        }
      ],
      "source": [
        "w_optimal, costs = logistic_regression(X_train_scratch, y_train_scratch,\n",
        "                                     iterations=2000, learning_rate=0.03,\n",
        "                                     print_costs=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atZ1hXhY-EOF",
        "outputId": "5a35a609-6aba-4fc8-84e4-db7227c23489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector trọng số: \n",
            " [[-4.01538473e+00]\n",
            " [-1.05327874e-03]\n",
            " [-2.86956158e-02]\n",
            " [ 3.16517431e-02]\n",
            " [-6.96871859e-02]\n",
            " [ 7.28591890e-02]\n",
            " [-1.37158613e-02]\n",
            " [-1.86655798e-02]\n",
            " [-5.81554234e-02]\n",
            " [-1.61153263e-02]\n",
            " [-4.52379947e-02]\n",
            " [-8.91799221e-02]\n",
            " [ 6.81410483e-02]\n",
            " [-1.10828214e-01]\n",
            " [-7.05927771e-03]\n",
            " [-1.55030804e-01]\n",
            " [-1.70214199e-03]\n",
            " [-7.04469008e-02]\n",
            " [-1.02680357e-01]\n",
            " [-2.94324350e-02]\n",
            " [ 8.58072383e-03]\n",
            " [ 3.75147872e-03]\n",
            " [ 1.71608624e-02]\n",
            " [ 3.63771619e-03]\n",
            " [-7.10500264e-04]\n",
            " [-5.84473743e-03]\n",
            " [-1.65487980e-03]\n",
            " [ 4.74300374e-03]\n",
            " [ 3.09478129e-03]\n",
            " [ 1.88106917e-03]\n",
            " [ 6.73271343e-03]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Vector trọng số: \\n\", w_optimal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.4 Đánh giá mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Yw9_CNVu-vYC"
      },
      "outputs": [],
      "source": [
        "y_pred_scratch = predict(X_test_scratch, w_optimal).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAcEKMKj-_jQ",
        "outputId": "547cb74f-7f94-4899-e1da-3822dcb542ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy:  0.9992451107756047\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_scratch = accuracy_score(y_test, y_pred_scratch)\n",
        "print(\"accuracy: \", accuracy_scratch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4 Triển khai thử trên thư viện Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Độ chính xác của mô hình: 99.93%\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Độ chính xác của mô hình: {:.2f}%\".format(accuracy * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Kết luận"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So sánh độ chính xác của mô hình tự triển khai và thư viện thì khá tương đồng, do đó mô hình tự triển khai khả năng cao là chính xác. Các tập dữ liệu của thầy có vẻ như là tập dữ liệu mẫu cho logistic regression nên độ chính xác đạt được rất cao."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
